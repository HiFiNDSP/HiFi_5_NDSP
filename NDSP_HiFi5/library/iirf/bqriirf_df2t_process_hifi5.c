/* ------------------------------------------------------------------------ */
/* Copyright (c) 2021 by Cadence Design Systems, Inc. ALL RIGHTS RESERVED.  */
/* These coded instructions, statements, and computer programs ('Cadence    */
/* Libraries') are the copyrighted works of Cadence Design Systems Inc.     */
/* Cadence IP is licensed for use with Cadence processor cores only and     */
/* must not be used for any other processors and platforms. Your use of the */
/* Cadence Libraries is subject to the terms of the license agreement you   */
/* have entered into with Cadence Design Systems, or a sublicense granted   */
/* to you by a direct Cadence license.                                     */
/* ------------------------------------------------------------------------ */
/*  IntegrIT, Ltd.   www.integrIT.com, info@integrIT.com                    */
/*                                                                          */
/* NatureDSP_Baseband Library                                               */
/*                                                                          */
/* This library contains copyrighted materials, trade secrets and other     */
/* proprietary information of IntegrIT, Ltd. This software is licensed for  */
/* use with Cadence processor cores only and must not be used for any other */
/* processors and platforms. The license to use these sources was given to  */
/* Cadence, Inc. under Terms and Condition of a Software License Agreement  */
/* between Cadence, Inc. and IntegrIT, Ltd.                                 */
/* ------------------------------------------------------------------------ */
/*          Copyright (C) 2009-2021 IntegrIT, Limited.                      */
/*                      All Rights Reserved.                                */
/* ------------------------------------------------------------------------ */

/*
  NatureDSP Signal Processing Library. IIR part
    Bi-quad Real Block IIR, floating point, Direct Form II transposed
    C code optimized for HiFi4
  IntegrIT, 2006-2019
*/

/*-------------------------------------------------------------------------
  Bi-quad Real Block IIR
  Computes a real IIR filter (cascaded IIR direct form I or II using 5 
  coefficients per bi-quad + gain term). Real input data are stored
  in vector x. The filter output result is stored in vector r. The filter 
  calculates N output samples using SOS and G matrices.
  NOTE:
  1. Bi-quad coefficients may be derived from standard SOS and G matrices 
  generated by MATLAB. However, typically biquad stages have big peaks 
  in their step response which may cause undesirable overflows at the 
  intermediate outputs. To avoid that the additional scale factors 
  coef_g[M] may be applied. These per-section scale factors may require 
  some tuning to find a compromise between quantization noise and possible 
  overflows. Output of the last section is directed to an additional 
  multiplier, with the gain factor being a power of two, either negative 
  or non-negative. It is specified through the total gain shift amount 
  parameter gain of each filter initialization function.
  2. 16x16 filters may suffer more from accumulation of the roundoff errors,
  so filters should be properly designed to match noise requirements
  3. Due to the performance reasons, IIR biquad filters may introduce 
  additional algorithmic delay of several sampless. Amount of that delay
  might be requested by the  xxx_groupDelay API. For sensitive applications
  all the filters have delayless implementations (with  _nd  suffix in the name).
  Formally, the xxx_groupDelay APIs is also implemented for that kind of filters,
  but return zero.
  
  Precision: 
  16x16         16-bit data, 16-bit coefficients, 16-bit intermediate 
                stage outputs (DF1, DF1 stereo, DF II form)
  32x16         32-bit data, 16-bit coefficients, 32-bit intermediate 
                (DF1, DF1 stereo, DF II form) stage outputs
  32x32         32-bit data, 32-bit coefficients, 32-bit intermediate 
                (DF I, DF1 stereo,  DF II form) stage outputs 
  f             floating point (DF I, DF1 stereo, DF II and DF IIt)

  Input:
  N             length of input sample block
  M             number of bi-quad sections
  S             1 for mono, 2 for stereo API
  s[]           scratch memory area (for fixed-point functions only). 
                Minimum number of bytes depends on selected filter structure 
                and precision:
                  BQRIIR16X16_DF1_SCRATCH_SIZE( N,  M ), or
                  BQRIIR16X16_DF2_SCRATCH_SIZE( N,  M ), or
                  BQRIIR32X16_DF1_SCRATCH_SIZE( N,  M ), or
                  BQRIIR32X16_DF2_SCRATCH_SIZE( N,  M ), or
                  BQRIIR32X32_DF1_SCRATCH_SIZE( N,  M ), or
                  BQRIIR32X32_DF2_SCRATCH_SIZE( N,  M ),
                  STEREO_BQRIIR16X16_DF1_SCRATCH_SIZE( N, M ) , or
                  STEREO_BQRIIR32X32_DF1_SCRATCH_SIZE( N, M ) , or
                  STEREO_BQRIIRF_DF1_SCRATCH_SIZE    ( N, M )
                 If a particular macro returns zero, then the corresponding
                 IIR doesn't require a scratch area and parameter s may 
                 hold zero.
  coef_sos[M*5]  filter coefficients stored in blocks of 5 numbers: 
                 b0 b1 b2 a1 a2. 
                 For fixed-point funcions, fixed point format of filter 
                 coefficients is Q1.14 for 16x16 and 32x16, or Q1.30 for 32x32 
  coef_sosl[M*5] filter coefficients for the left channel (stereo filters only)
  coef_sosr[M*5] filter coefficients for the left channel (stereo filters only)
  coef_g[M]      scale factor for each section, Q15 (for fixed-point 
                 functions only)
  coef_gl[M]     scale factor for the left channel (stereo filters only)
  coef_gr[M]     scale factor for the right channel (stereo filters only)
  gain           total gain shift amount applied to output signal of the
                 last section, -48..15
  gainl          total gain shift amount  for the left channel (stereo filters 
                 only)
  gainr          total gain shift amount for the right channel (stereo filters 
                 only)

  x[N*S]         input samples, Q15, Q31 or floating point. Stereo samples 
                 go in interleaved order (left, right)
  Output:
  r[N*S]         output data, Q15, Q31 or floating point. Stereo samples go 
                 in interleaved order (left, right) 

  Restriction:
  x,r,s,coef_g,coef_sos should not overlap
  N   - must be a multiple of 2
  s[] - whenever supplied must be aligned on an 16-bytes boundary
-------------------------------------------------------------------------*/

/* Portable data types. */
#include "NatureDSP_types.h"
/* Signal Processing Library API. */
#include "NatureDSP_Signal_iir.h"
/* Common utility and macros declarations. */
#include "common.h"
#include "bqriirf_df2t.h"
#include "common_fpu.h"

#if (HAVE_VFPU==0 && HAVE_FPU==0)
DISCARD_FUN(void,bqriirf_df2t,( bqriirf_df2t_handle_t _bqriir,
                      float32_t * restrict       z,
                const float32_t *            x, int N))
#elif (HAVE_VFPU)

// Process data. The filter instance is identified with a handle returned by
// the initializing function.
void bqriirf_df2t( bqriirf_df2t_handle_t _bqriir,
                   float32_t *  restrict       z,
             const float32_t *                 x, int N)
{
    bqriirf_df2t_t *state;
    const ae_int32x2 * restrict pX;
          ae_int32x2 * restrict pZ;
    const xtfloatx2  * restrict pa1,
                     * restrict pa2,
                     * restrict pb0,
                     * restrict pb1,
                     * restrict pb2;
    const xtfloatx4  * restrict pDrd;
          xtfloatx4  * restrict pDwr;
    xtfloatx2 dx0,dz0,dw0,t0;
    xtfloatx2 dx1,dz1,dw1,t1;
    xtfloatx2 dx2,dz2,dw2,t2;
    xtfloatx2 dx3,dz3,dw3,t3;
    xtfloatx2 a10,a20,b00,b10,b20;
    xtfloatx2 a11,a21,b01,b11,b21;
    xtfloatx2 a12,a22,b02,b12,b22;
    xtfloatx2 a13,a23,b03,b13,b23;
    xtfloatx2 scale;
    int n,m;
    int M;
    NASSERT(_bqriir);
    if(N<=0) return;
    NASSERT(N%2==0);
    NASSERT(x);
    NASSERT(z);
    state=(bqriirf_df2t_t*)(_bqriir);
    NASSERT(state);
    NASSERT(state->st);
    NASSERT(state->cf);
    M=state->M;
    
    /* Initialize pointers */
    pX  =(const ae_int32x2 *)(x);
    pb0 =(const xtfloatx2 *)(state->cf);
    pDrd=(const xtfloatx4 *)(state->st);
    pDwr=(      xtfloatx4 *)(state->st);
    
    /* Process samples by 4 sections */
    for (m = 0; m < (M>>3); m++)
    {
        ae_int32x2 tmp,out;
        pZ=(ae_int32x2 *)(z);
        /* load delay lines */
        AE_LSX2X2_IP(dx0, dx1, pDrd, 4*sizeof(float32_t));
        AE_LSX2X2_IP(dx2, dx3, pDrd, 4*sizeof(float32_t));
        AE_LSX2X2_IP(dz0, dz1, pDrd, 4*sizeof(float32_t));
        AE_LSX2X2_IP(dz2, dz3, pDrd, 4*sizeof(float32_t));
        AE_LSX2X2_IP(dw0, dw1, pDrd, 4*sizeof(float32_t));
        AE_LSX2X2_IP(dw2, dw3, pDrd, 4*sizeof(float32_t));
        /* load part of filter coefficients */
        AE_LSX2X2_I(b00, b01, (const xtfloatx4 *)pb0, 0*4*sizeof(float32_t));
        AE_LSX2X2_I(b10, b11, (const xtfloatx4 *)pb0, 1*4*sizeof(float32_t));
        AE_LSX2X2_I(b20, b21, (const xtfloatx4 *)pb0, 2*4*sizeof(float32_t));

        /* processing loop  */
        __Pragma("loop_count factor=2");
        for (n = 0; n < N; n++)
        {
            /* Reload coefficients on every iteration */
            AE_LSX2X2_I(a10, a11, (const xtfloatx4 *)pb0, 3*4*sizeof(float32_t));
            AE_LSX2X2_I(a20, a21, (const xtfloatx4 *)pb0, 4*4*sizeof(float32_t));
            AE_LSX2X2_I(b02, b03, (const xtfloatx4 *)pb0, 5*4*sizeof(float32_t));
            AE_LSX2X2_I(b12, b13, (const xtfloatx4 *)pb0, 6*4*sizeof(float32_t));
            AE_LSX2X2_I(b22, b23, (const xtfloatx4 *)pb0, 7*4*sizeof(float32_t));
            AE_LSX2X2_X(a12, a13, (const xtfloatx4 *)pb0, 8*4*sizeof(float32_t));
            AE_LSX2X2_X(a22, a23, (const xtfloatx4 *)pb0, 9*4*sizeof(float32_t));
            /* load input sample */
            AE_L32_IP(tmp, castxcc(ae_int32,pX), sizeof(float32_t));
            t0=XT_AE_MOVXTFLOATX2_FROMINT32X2(tmp);

            /* save previously computed sample */
            out=XT_AE_MOVINT32X2_FROMXTFLOATX2(dx3); 
            AE_S32_L_IP(out,castxcc(ae_int32,pZ),sizeof(float32_t));

            /* update delay lines */
            t3=AE_SEL32_LH_SX2(dx2,dx3);
            t2=AE_SEL32_LH_SX2(dx1,dx2);
            t1=AE_SEL32_LH_SX2(dx0,dx1);
            t0=AE_SEL32_LH_SX2(t0 ,dx0);

            /* perform multiplications for 8 biquads */
            dx0 = dz0;
            dx1 = dz1;
            MADD_SX2X2(dx0, dx1, b00, b01,  t0,  t1);
             MUL_SX2X2(dz0, dz1, b10, b11,  t0,  t1);
             ADD_SX2X2(dz0, dz1, dz0, dz1, dw0, dw1);
            MSUB_SX2X2(dz0, dz1, a10, a11, dx0, dx1);
             MUL_SX2X2(dw0, dw1, b20, b21,  t0,  t1);
            MSUB_SX2X2(dw0, dw1, a20, a21, dx0, dx1);
            dx2 = dz2;
            dx3 = dz3;
            MADD_SX2X2(dx2, dx3, b02, b03,  t2,  t3);
             MUL_SX2X2(dz2, dz3, b12, b13,  t2,  t3);
             ADD_SX2X2(dz2, dz3, dz2, dz3, dw2, dw3);
            MSUB_SX2X2(dz2, dz3, a12, a13, dx2, dx3);
             MUL_SX2X2(dw2, dw3, b22, b23,  t2,  t3);
            MSUB_SX2X2(dw2, dw3, a22, a23, dx2, dx3);
        }
        /* jump to the next 4 sections */
        pb0 += 20;
        /* save delay lines */
        AE_SSX2X2_IP(dx0, dx1, pDwr, 4*sizeof(float32_t));
        AE_SSX2X2_IP(dx2, dx3, pDwr, 4*sizeof(float32_t));
        AE_SSX2X2_IP(dz0, dz1, pDwr, 4*sizeof(float32_t));
        AE_SSX2X2_IP(dz2, dz3, pDwr, 4*sizeof(float32_t));
        AE_SSX2X2_IP(dw0, dw1, pDwr, 4*sizeof(float32_t));
        AE_SSX2X2_IP(dw2, dw3, pDwr, 4*sizeof(float32_t));
        /* switch pointer to the input data to the pointer to the output */
        pX=(const ae_int32x2 *)(z);
    }
    if (M & 4)
    {
        ae_int32x2 tmp,out;
        pZ=(ae_int32x2 *)(z);
        /* load delay lines */
        AE_LSX2X2_IP(dx0, dx1, pDrd, 4*sizeof(float32_t));
        AE_LSX2X2_IP(dz0, dz1, pDrd, 4*sizeof(float32_t));
        AE_LSX2X2_IP(dw0, dw1, pDrd, 4*sizeof(float32_t));
        /* load filter coefficients */
        AE_LSX2X2_I(b00, b01, (const xtfloatx4 *)pb0,  0*sizeof(float32_t));
        AE_LSX2X2_I(b10, b11, (const xtfloatx4 *)pb0,  4*sizeof(float32_t));
        AE_LSX2X2_I(b20, b21, (const xtfloatx4 *)pb0,  8*sizeof(float32_t));
        AE_LSX2X2_I(a10, a11, (const xtfloatx4 *)pb0, 12*sizeof(float32_t));
        AE_LSX2X2_X(a20, a21, (const xtfloatx4 *)pb0, 16*sizeof(float32_t));

        /* processing loop  */
        __Pragma("loop_count factor=2");
        for (n = 0; n < N; n++)
        {
            /* load input sample */
            AE_L32_IP(tmp, castxcc(ae_int32,pX), sizeof(float32_t));
            t0=XT_AE_MOVXTFLOATX2_FROMINT32X2(tmp);

            /* save previously computed sample */
            out=XT_AE_MOVINT32X2_FROMXTFLOATX2(dx1); 
            AE_S32_L_IP(out,castxcc(ae_int32,pZ),sizeof(float32_t));

            /* update delay lines */
            t1 = AE_SEL32_LH_SX2(dx0, dx1);
            t0 = AE_SEL32_LH_SX2( t0, dx0);
            /* perform multiplications for 4 biquads */
            dx0 = dz0;
            dx1 = dz1;
            MADD_SX2(dx0, b00, t0);
            MADD_SX2(dx1, b01, t1);
            dz0 = MUL_SX2(b10, t0);
            dz1 = MUL_SX2(b11, t1);
            dz0 = dz0 + dw0;
            dz1 = dz1 + dw1;
            MSUB_SX2(dz0, a10, dx0);
            MSUB_SX2(dz1, a11, dx1);
            dw0 = MUL_SX2(b20, t0);
            dw1 = MUL_SX2(b21, t1);
            MSUB_SX2(dw0, a20, dx0);
            MSUB_SX2(dw1, a21, dx1);
        }
        /* jump to the next 4 sections */
        pb0 += 10;
        /* save delay lines */
        AE_SSX2X2_IP(dx0, dx1, pDwr, 4*sizeof(float32_t));
        AE_SSX2X2_IP(dz0, dz1, pDwr, 4*sizeof(float32_t));
        AE_SSX2X2_IP(dw0, dw1, pDwr, 4*sizeof(float32_t));
        /* switch pointer to the input data to the pointer to the output */
        pX=(const ae_int32x2 *)(z);
    }
    /* Process last M%4 sections */
    M = M & 3;
    pb1 = (const xtfloatx2*)((float32_t *)pb0 + M);
    pb2 = (const xtfloatx2*)((float32_t *)pb1 + M);
    pa1 = (const xtfloatx2*)((float32_t *)pb2 + M);
    pa2 = (const xtfloatx2*)((float32_t *)pa1 + M);
    /* comput gain */
    {
        int32_t s;
        s=state->gain;
        s=((s+127)&255)<<23;
        scale = AE_MOVXTFLOATX2_FROMF32X2(AE_MOVDA32X2(s,s));
    }
    if (M == 3)
    {
        xtfloat dw;
        ae_int32x2 tmp, out;
        ae_valign al_cf;
        pZ=(ae_int32x2 *)(z);
        /* load delay lines */
        AE_LSX2X2_IP(dx0, dz0, pDrd, 4*sizeof(float32_t));
        AE_LSX2X2_IP(dw0, dz1, pDrd, 4*sizeof(float32_t));
        dw = AE_LSI((const xtfloat *)pDrd, 0);
        dx1 = AE_SEL32_HH_SX2(dz1, dz1);
        dw1 = dw;
        /* load filter coefficients */
        al_cf = AE_LA64_PP(pb0); AE_LASX2IP(b00, al_cf, pb0); b01 = AE_LSI((const xtfloat *)pb0, 0);
        al_cf = AE_LA64_PP(pb1); AE_LASX2IP(b10, al_cf, pb1); b11 = AE_LSI((const xtfloat *)pb1, 0);
        al_cf = AE_LA64_PP(pb2); AE_LASX2IP(b20, al_cf, pb2); b21 = AE_LSI((const xtfloat *)pb2, 0);
        al_cf = AE_LA64_PP(pa1); AE_LASX2IP(a10, al_cf, pa1); a11 = AE_LSI((const xtfloat *)pa1, 0);
        al_cf = AE_LA64_PP(pa2); AE_LASX2IP(a20, al_cf, pa2); a21 = AE_LSI((const xtfloat *)pa2, 0);

        /* processing loop  */
        __Pragma("loop_count factor=2");
        for (n = 0; n < N; n++)
        {
            /* load input sample */
            AE_L32_IP(tmp, castxcc(ae_int32,pX), sizeof(float32_t));
            t0=XT_AE_MOVXTFLOATX2_FROMINT32X2(tmp);

            /* save previously computed sample */
            dx1 = MUL_SX2(dx1, scale);
            out = XT_AE_MOVINT32X2_FROMXTFLOATX2(dx1); 
            AE_S32_L_IP(out,castxcc(ae_int32,pZ),sizeof(float32_t));

            /* update delay lines */
            t1 = dx0;
            t0 = AE_SEL32_LH_SX2(t0, dx0);
            /* perform multiplications for 4 biquads */
            dx0 = dz0;
            dx1 = dz1;
            MADD_SX2(dx0, b00, t0);
            MADD_SX2(dx1, b01, t1);
            dz0 = MUL_SX2(b10, t0);
            dz1 = MUL_SX2(b11, t1);
            dz0 = dz0 + dw0;
            dz1 = dz1 + dw1;
            MSUB_SX2(dz0, a10, dx0);
            MSUB_SX2(dz1, a11, dx1);
            dw0 = MUL_SX2(b20, t0);
            dw1 = MUL_SX2(b21, t1);
            MSUB_SX2(dw0, a20, dx0);
            MSUB_SX2(dw1, a21, dx1);
        }
        /* save delay lines */
        dz1 = AE_SEL32_LL_SX2(dx1, dz1);
        dw = dw1;
        AE_SSX2X2_IP(dx0, dz0, pDwr, 4*sizeof(float32_t));
        AE_SSX2X2_IP(dw0, dz1, pDwr, 4*sizeof(float32_t));
        AE_SSI(dw, (xtfloat *)pDwr, 0);
    }
    else if (M == 2)
    {
        ae_valign al_cf;
        pZ=(ae_int32x2 *)z;
        /* load delay lines */
        AE_LSX2IP(dx0, castxcc(xtfloatx2,pDrd), 2*sizeof(float32_t));
        AE_LSX2IP(dz0, castxcc(xtfloatx2,pDrd), 2*sizeof(float32_t));
        AE_LSX2IP(dw0, castxcc(xtfloatx2,pDrd), 2*sizeof(float32_t));
        /* load filter coefficients */
        AE_LSX2IP(b00, pb0, 2*sizeof(float32_t));
        al_cf = AE_LASX2PP(pb1);  AE_LASX2IP(b10, al_cf, pb1);
        AE_LSX2IP(b20, pb2, 2*sizeof(float32_t));
        al_cf = AE_LASX2PP(pa1);  AE_LASX2IP(a10, al_cf, pa1);
        AE_LSX2IP(a20, pa2, 2*sizeof(float32_t));
        /* processing loop  */
        __Pragma("loop_count factor=2");
        for (n = 0; n < N; n++)
        {
            ae_int32x2 tmp, out;
            /* load input sample */
            AE_L32_IP(tmp, castxcc(ae_int32,pX), sizeof(float32_t));
            t0=AE_MOVXTFLOATX2_FROMINT32X2(tmp);
            /* save previously computed sample */
            out=AE_MOVINT32X2_FROMXTFLOATX2(MUL_SX2(dx0, scale));
            AE_S32_L_IP(out, castxcc(ae_int32,pZ),sizeof(float32_t));

            /* update delay lines */
            t0 = AE_SEL32_LH_SX2(t0, dx0);
            /* perform multiplications for 2 biquads */
            dx0 = dz0;
            MADD_SX2(dx0, b00, t0);
            dz0 = MUL_SX2(b10, t0);
            dz0 = dz0 + dw0;
            MSUB_SX2(dz0, a10, dx0); 
            dw0 = MUL_SX2(b20, t0);
            MSUB_SX2(dw0, a20, dx0);
        }
        /* save delay lines */
        AE_SSX2IP(dx0, castxcc(xtfloatx2,pDwr), 2*sizeof(float32_t));
        AE_SSX2IP(dz0, castxcc(xtfloatx2,pDwr), 2*sizeof(float32_t));
        AE_SSX2IP(dw0, castxcc(xtfloatx2,pDwr), 2*sizeof(float32_t));
        /* switch pointer to the input data to the pointer to the output */
        pX=(const ae_int32x2 *)(z);
    }
    else if (M == 1)
    {
        xtfloat dx,dz,dw,t;
        xtfloat a1,a2,b0,b1,b2;
        xtfloat scl, out;
        pZ=(ae_int32x2 *)z;
        /* load delay lines and coefficients */
        dx = AE_LSI((const xtfloat *)pDrd,0*sizeof(float32_t)); 
        dz = AE_LSI((const xtfloat *)pDrd,1*sizeof(float32_t)); 
        dw = AE_LSI((const xtfloat *)pDrd,2*sizeof(float32_t)); 
        b0 = AE_LSI((const xtfloat *)pb0,0);
        b1 = AE_LSI((const xtfloat *)pb1,0);
        b2 = AE_LSI((const xtfloat *)pb2,0);
        a1 = AE_LSI((const xtfloat *)pa1,0);
        a2 = AE_LSI((const xtfloat *)pa2,0);
        scl = scale;
        /* processing loop */
        for (n=0; n<N; n++)
        {
            out = MUL_S(dx, scl);            
            AE_LSIP(t,castxcc(xtfloat,pX),sizeof(float32_t));
            AE_SSIP(out,castxcc(xtfloat,pZ),sizeof(float32_t));

            dx = dz;
            MADD_S(dx, b0, t);
            dz = MUL_S(b1, t);
            dz = ADD_S(dz, dw);
            MSUB_S(dz, a1, dx); 
            dw = MUL_S(b2, t);
            MSUB_S(dw, a2, dx);
        }
        AE_SSI(dx,(xtfloat *)pDwr,0*sizeof(float32_t));
        AE_SSI(dz,(xtfloat *)pDwr,1*sizeof(float32_t));
        AE_SSI(dw,(xtfloat *)pDwr,2*sizeof(float32_t));
        /* switch pointer to the input data to the pointer to the output */
        pX=(const ae_int32x2 *)(z);
    }
    else /* final scaling if M is a multiple of 4 */
    {
        xtfloatx2 x0, x1;
        ae_valignx2 alX, alZ;
        pZ = (ae_int32x2 *)z;
        alX = AE_LA128_PP(pX);
        alZ = AE_ZALIGN128();
        __Pragma("ymemory (pZ)");
        for (n = 0; n < (N>>2); n++)
        {
            AE_LASX2X2_IP(x0, x1, alX, castxcc(xtfloatx4,pX));
            MUL_SX2X2(x0, x1, x0, x1, scale, scale);
            AE_SASX2X2_IP(x0, x1, alZ, castxcc(xtfloatx4,pZ));
        }
        AE_SA128POS_FP(alZ, pZ);
        if (N & 2)
        {
            ae_valign al_px, al_pz;
            al_pz = AE_ZALIGN64();

            al_px = AE_LA64_PP(pX);
            AE_LASX2IP(x0, al_px, castxcc(xtfloatx2,pX));
            x0 = MUL_SX2(x0, scale);
            AE_SASX2IP(x0, al_pz, castxcc(xtfloatx2,pZ));
            AE_SA64POS_FP(al_pz, pZ);
        }
    }
}/* bqriirf_df2t_process() */
#else 
// code for scalar FPU
void bqriirf_df2t( bqriirf_df2t_handle_t _bqriir,
                   float32_t *  restrict       z,
             const float32_t *                 x, int N)
{
    bqriirf_df2t_t *state;
    const xtfloat *cf;
    const xtfloat * restrict pDrd;
          xtfloat * restrict pDwr;
    const xtfloat * pX;
          xtfloat * pZ;
    const xtfloat * restrict pXr;
          xtfloat * restrict pZr;
    float32_t scale;
    int32_t s;
    int n,m;
    int M;
    NASSERT(_bqriir);
    state=(bqriirf_df2t_t*)(_bqriir);
    if(N<=0) return;
    NASSERT(N%2==0);
    NASSERT(x);
    NASSERT(z);
    NASSERT(state);
    NASSERT(state->st);
    NASSERT(state->cf);
    M=state->M;
    cf=(const xtfloat*)state->cf;
    pDrd=(const xtfloat*)state->st;
    pDwr=(      xtfloat*)state->st;
    s=state->gain;
    s=((s+127)&255)<<23;
    scale=XT_WFR(s);

    for (m=0; m<M; m++,x=z)
    {
        xtfloat a1,a2,b0,b1,b2,dx,dz,dw;
        pX=(const xtfloat*)x;
        pZ=(      xtfloat*)z;
        XT_LSIP(dx,pDrd,sizeof(xtfloat));
        XT_LSIP(dz,pDrd,sizeof(xtfloat));
        XT_LSIP(dw,pDrd,sizeof(xtfloat));
        XT_LSIP(b0,cf,sizeof(xtfloat));
        XT_LSIP(b1,cf,sizeof(xtfloat));
        XT_LSIP(b2,cf,sizeof(xtfloat));
        XT_LSIP(a1,cf,sizeof(xtfloat));
        XT_LSIP(a2,cf,sizeof(xtfloat));
        for (n=0;n<N;n+=2)
        {
            xtfloat t,u0,u1;
            XT_LSIP(u0,pX,sizeof(xtfloat));
            XT_LSIP(u1,pX,sizeof(xtfloat));
            XT_SSIP(dx,pZ,sizeof(xtfloat));
            t=dz;  XT_MADD_S(t,b0,u0);
            dz=dw; XT_MADD_S(dz,b1,u0);
            XT_MSUB_S(dz,a1,t) ;
            dw =XT_MUL_S(b2,u0);
            XT_MSUB_S(dw,a2,t);
            dx =t;
            XT_SSIP(dx,pZ,sizeof(xtfloat));
            t=dz;  XT_MADD_S(t,b0,u1);
            dz=dw; XT_MADD_S(dz,b1,u1);
            XT_MSUB_S(dz,a1,t) ;
            dw =XT_MUL_S(b2,u1);
            XT_MSUB_S(dw,a2,t);
            dx =t;
        }
        XT_SSIP(dx,pDwr,sizeof(xtfloat));
        XT_SSIP(dz,pDwr,sizeof(xtfloat));
        XT_SSIP(dw,pDwr,sizeof(xtfloat));
    }
    __Pragma("no_reorder")
    /* final scaling */
    {
        pZr=(      xtfloat*)z;
        pXr=(const xtfloat*)x;
        for (n=0; n<(N>>1); n++)
        {
            xtfloat x0,x1;
            XT_LSIP(x0,pXr,sizeof(xtfloat));
            XT_LSIP(x1,pXr,sizeof(xtfloat));
            XT_SSIP(XT_MUL_S(x0,scale),pZr,sizeof(xtfloat));
            XT_SSIP(XT_MUL_S(x1,scale),pZr,sizeof(xtfloat));
        }
    }
}

#endif
