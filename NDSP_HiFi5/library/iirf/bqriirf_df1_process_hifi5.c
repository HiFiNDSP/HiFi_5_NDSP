/* ------------------------------------------------------------------------ */
/* Copyright (c) 2021 by Cadence Design Systems, Inc. ALL RIGHTS RESERVED.  */
/* These coded instructions, statements, and computer programs ('Cadence    */
/* Libraries') are the copyrighted works of Cadence Design Systems Inc.     */
/* Cadence IP is licensed for use with Cadence processor cores only and     */
/* must not be used for any other processors and platforms. Your use of the */
/* Cadence Libraries is subject to the terms of the license agreement you   */
/* have entered into with Cadence Design Systems, or a sublicense granted   */
/* to you by a direct Cadence license.                                     */
/* ------------------------------------------------------------------------ */
/*  IntegrIT, Ltd.   www.integrIT.com, info@integrIT.com                    */
/*                                                                          */
/* NatureDSP_Baseband Library                                               */
/*                                                                          */
/* This library contains copyrighted materials, trade secrets and other     */
/* proprietary information of IntegrIT, Ltd. This software is licensed for  */
/* use with Cadence processor cores only and must not be used for any other */
/* processors and platforms. The license to use these sources was given to  */
/* Cadence, Inc. under Terms and Condition of a Software License Agreement  */
/* between Cadence, Inc. and IntegrIT, Ltd.                                 */
/* ------------------------------------------------------------------------ */
/*          Copyright (C) 2009-2021 IntegrIT, Limited.                      */
/*                      All Rights Reserved.                                */
/* ------------------------------------------------------------------------ */

/*
  NatureDSP Signal Processing Library. IIR part
    Bi-quad Real Block IIR, floating point, Direct Form I
    C code optimized for HiFi4
  IntegrIT, 2006-2019
*/

/*-------------------------------------------------------------------------
  Bi-quad Real Block IIR
  Computes a real IIR filter (cascaded IIR direct form I or II using 5 
  coefficients per bi-quad + gain term). Real input data are stored
  in vector x. The filter output result is stored in vector r. The filter 
  calculates N output samples using SOS and G matrices.
  NOTE:
  1. Bi-quad coefficients may be derived from standard SOS and G matrices 
  generated by MATLAB. However, typically biquad stages have big peaks 
  in their step response which may cause undesirable overflows at the 
  intermediate outputs. To avoid that the additional scale factors 
  coef_g[M] may be applied. These per-section scale factors may require 
  some tuning to find a compromise between quantization noise and possible 
  overflows. Output of the last section is directed to an additional 
  multiplier, with the gain factor being a power of two, either negative 
  or non-negative. It is specified through the total gain shift amount 
  parameter gain of each filter initialization function.
  2. 16x16 filters may suffer more from accumulation of the roundoff errors,
  so filters should be properly designed to match noise requirements
  3. Due to the performance reasons, IIR biquad filters may introduce 
  additional algorithmic delay of several sampless. Amount of that delay
  might be requested by the  xxx_groupDelay API. For sensitive applications
  all the filters have delayless implementations (with  _nd  suffix in the name).
  Formally, the xxx_groupDelay APIs is also implemented for that kind of filters,
  but return zero.
  
  Precision: 
  16x16         16-bit data, 16-bit coefficients, 16-bit intermediate 
                stage outputs (DF1, DF1 stereo, DF II form)
  32x16         32-bit data, 16-bit coefficients, 32-bit intermediate 
                (DF1, DF1 stereo, DF II form) stage outputs
  32x32         32-bit data, 32-bit coefficients, 32-bit intermediate 
                (DF I, DF1 stereo,  DF II form) stage outputs 
  f             floating point (DF I, DF1 stereo, DF II and DF IIt)

  Input:
  N             length of input sample block
  M             number of bi-quad sections
  S             1 for mono, 2 for stereo API
  s[]           scratch memory area (for fixed-point functions only). 
                Minimum number of bytes depends on selected filter structure 
                and precision:
                  BQRIIR16X16_DF1_SCRATCH_SIZE( N,  M ), or
                  BQRIIR16X16_DF2_SCRATCH_SIZE( N,  M ), or
                  BQRIIR32X16_DF1_SCRATCH_SIZE( N,  M ), or
                  BQRIIR32X16_DF2_SCRATCH_SIZE( N,  M ), or
                  BQRIIR32X32_DF1_SCRATCH_SIZE( N,  M ), or
                  BQRIIR32X32_DF2_SCRATCH_SIZE( N,  M ),
                  STEREO_BQRIIR16X16_DF1_SCRATCH_SIZE( N, M ) , or
                  STEREO_BQRIIR32X32_DF1_SCRATCH_SIZE( N, M ) , or
                  STEREO_BQRIIRF_DF1_SCRATCH_SIZE    ( N, M )
                 If a particular macro returns zero, then the corresponding
                 IIR doesn't require a scratch area and parameter s may 
                 hold zero.
  coef_sos[M*5]  filter coefficients stored in blocks of 5 numbers: 
                 b0 b1 b2 a1 a2. 
                 For fixed-point funcions, fixed point format of filter 
                 coefficients is Q1.14 for 16x16 and 32x16, or Q1.30 for 32x32 
  coef_sosl[M*5] filter coefficients for the left channel (stereo filters only)
  coef_sosr[M*5] filter coefficients for the left channel (stereo filters only)
  coef_g[M]      scale factor for each section, Q15 (for fixed-point 
                 functions only)
  coef_gl[M]     scale factor for the left channel (stereo filters only)
  coef_gr[M]     scale factor for the right channel (stereo filters only)
  gain           total gain shift amount applied to output signal of the
                 last section, -48..15
  gainl          total gain shift amount  for the left channel (stereo filters 
                 only)
  gainr          total gain shift amount for the right channel (stereo filters 
                 only)

  x[N*S]         input samples, Q15, Q31 or floating point. Stereo samples 
                 go in interleaved order (left, right)
  Output:
  r[N*S]         output data, Q15, Q31 or floating point. Stereo samples go 
                 in interleaved order (left, right) 

  Restriction:
  x,r,s,coef_g,coef_sos should not overlap
  N   - must be a multiple of 2
  s[] - whenever supplied must be aligned on an 16-bytes boundary
-------------------------------------------------------------------------*/

/* Portable data types. */
#include "NatureDSP_types.h"
/* Signal Processing Library API. */
#include "NatureDSP_Signal_iir.h"
/* Common utility and macros declarations. */
#include "common.h"
#include "bqriirf_df1.h"
#include "common_fpu.h"

#if (HAVE_VFPU==0 && HAVE_FPU==0)
DISCARD_FUN(void,bqriirf_df1,( bqriirf_df1_handle_t restrict _bqriir,
                      float32_t *       z,
                const float32_t *       x, int N))
#elif (HAVE_VFPU)

// Process data. The filter instance is identified with a handle returned by
// the initializing function.
void bqriirf_df1( bqriirf_df1_handle_t restrict _bqriir,
                  float32_t *                   z,
            const float32_t *                   x, int N)
{
    bqriirf_df1_t    * restrict state;
    const ae_int32x2 * restrict pX;
          ae_int32x2 * restrict pZ;
    const xtfloatx2  * restrict pa1,
                     * restrict pa2,
                     * restrict pb0,
                     * restrict pb1,
                     * restrict pb2;
    const xtfloatx4  * restrict pDrd;
          xtfloatx4  * restrict pDwr;
    xtfloatx2 dx00,dx10,dy00,dy10,dz0,t;
    xtfloatx2      dx11,dy01,dy11,dz1;
    xtfloatx2 a10,a20,b00,b10,b20;
    xtfloatx2 a11,a21,b01,b11,b21;
    xtfloatx2 scale;
    int n,m;
    int M;

    NASSERT(_bqriir);
    if(N<2) return;
    NASSERT(N%2==0);
    NASSERT(x);
    NASSERT(z);
    state=(bqriirf_df1_t*)(_bqriir);
    NASSERT(state);
    NASSERT(state->st);
    NASSERT(state->cf);
    M=state->M;
    NASSERT(M>0);

    {
        int32_t s;
        s=state->gain;
        s=((s+127)&255)<<23;
        scale = XT_AE_MOVXTFLOATX2_FROMF32X2(AE_MOVDA32(s));
    }
    /* Initialize pointers */
    pX  =(const ae_int32x2*)x;
    pb0 =(const xtfloatx2*)(state->cf);
    pDrd=(const xtfloatx4*)(state->st);
    pDwr=(      xtfloatx4*)(state->st);
    /* Process samples by 8 sections */
    for (m = 0; m < (M>>3); m++)
    {
        xtfloatx2 dx02,dx12,dy02,dy12,dz2;
        xtfloatx2      dx13,dy03,dy13,dz3;
        xtfloatx2 a12,a22,b02,b12,b22;
        xtfloatx2 a13,a23,b03,b13,b23;

        pZ=(ae_int32x2 *)z;
        /* load delay lines */
        AE_LSX2X2_IP(dx00, dx10, pDrd, 4*sizeof(float32_t));
        AE_LSX2X2_IP(dx11, dy00, pDrd, 4*sizeof(float32_t));
        AE_LSX2X2_IP(dy01, dy10, pDrd, 4*sizeof(float32_t));
        AE_LSX2X2_IP(dy11, dx02, pDrd, 4*sizeof(float32_t));
        AE_LSX2X2_IP(dx12, dx13, pDrd, 4*sizeof(float32_t));
        AE_LSX2X2_IP(dy02, dy03, pDrd, 4*sizeof(float32_t));
        AE_LSX2X2_IP(dy12, dy13, pDrd, 4*sizeof(float32_t));

        /* preload filter coefficients */
        AE_LSX2X2_I(b00, b01, (const xtfloatx4*)pb0, 0*sizeof(float32_t));
        AE_LSX2X2_I(b10, b11, (const xtfloatx4*)pb0, 4*sizeof(float32_t));
        pb1 = pb0 + 2*2;
        pb2 = pb1 + 2*4;

        /* processing loop */
        __Pragma("loop_count factor=2");
        for (n = 0; n < N; n++)
        {
            xtfloatx2 in0, in2;
            ae_int32x2 tmp;
            /* load input sample */
            AE_L32_IP(tmp,castxcc(ae_int32,pX),sizeof(float32_t)); t=XT_AE_MOVXTFLOATX2_FROMINT32X2(tmp);

            AE_LSX2X2_X(b20, b21, (const xtfloatx4*)pb1, 0*4*sizeof(float32_t));
            AE_LSX2X2_X(a10, a11, (const xtfloatx4*)pb1, 1*4*sizeof(float32_t));
            AE_LSX2X2_X(a20, a21, (const xtfloatx4*)pb1, 2*4*sizeof(float32_t));
            AE_LSX2X2_X(b02, b03, (const xtfloatx4*)pb1, 3*4*sizeof(float32_t));
            AE_LSX2X2_X(b12, b13, (const xtfloatx4*)pb2, 0*4*sizeof(float32_t));
            AE_LSX2X2_X(b22, b23, (const xtfloatx4*)pb2, 1*4*sizeof(float32_t));
            AE_LSX2X2_X(a12, a13, (const xtfloatx4*)pb2, 2*4*sizeof(float32_t));
            AE_LSX2X2_X(a22, a23, (const xtfloatx4*)pb2, 3*4*sizeof(float32_t));

            /* perform multiplications for 4 biquads */
            in0 = XT_SEL32_LH_SX2(t,dy01);
            MUL_SX2X2 (dz0, dz1, b20, b21, dx10, dx11);
            MSUB_SX2X2(dz0, dz1, a20, a21, dy10, dy11);
            MADD_SX2X2(dz0, dz1, b10, b11, dx00, dy10);
            MSUB_SX2X2(dz0, dz1, a10, a11, dy00, dy01);
            MADD_SX2X2(dz0, dz1, b00, b01, in0 , dy00);

            /* perform multiplications for next 4 biquads */
            in2 = XT_SEL32_LH_SX2(dz1,dy03);
            MUL_SX2X2 (dz2, dz3, b22, b23, dx12, dx13);
            MSUB_SX2X2(dz2, dz3, a22, a23, dy12, dy13);
            MADD_SX2X2(dz2, dz3, b12, b13, dx02, dy12);
            MSUB_SX2X2(dz2, dz3, a12, a13, dy02, dy03);
            MADD_SX2X2(dz2, dz3, b02, b03, in2 , dy02);

            /* shift delay lines */
            dx10 = dx00;
            dx11 = dy10;
            dx00 = in0;
            dy10 = dy00;
            dy11 = dy01;
            dy00 = dz0;
            dy01 = dz1;

            dx12 = dx02;
            dx13 = dy12;
            dx02 = in2;
            dy12 = dy02;
            dy13 = dy03;
            dy02 = dz2;
            dy03 = dz3;

            /* save computed sample */
            tmp=XT_AE_MOVINT32X2_FROMXTFLOATX2(dz3);
            AE_S32_L_IP(tmp,castxcc(ae_int32,pZ),sizeof(float32_t));
        }
        /* jump to the next 8 sections */
        pb0 += 20;
        /* update delay lines */
        AE_SSX2X2_IP(dx00, dx10, pDwr, 4*sizeof(float32_t));
        AE_SSX2X2_IP(dx11, dy00, pDwr, 4*sizeof(float32_t));
        AE_SSX2X2_IP(dy01, dy10, pDwr, 4*sizeof(float32_t));
        AE_SSX2X2_IP(dy11, dx02, pDwr, 4*sizeof(float32_t));
        AE_SSX2X2_IP(dx12, dx13, pDwr, 4*sizeof(float32_t));
        AE_SSX2X2_IP(dy02, dy03, pDwr, 4*sizeof(float32_t));
        AE_SSX2X2_IP(dy12, dy13, pDwr, 4*sizeof(float32_t));

        pX=(const ae_int32x2*)z;/* switch pointer to the input data to the pointer to the output */
    }

    if (M & 4)
    {
        pZ=(ae_int32x2 *)z;
        /* load delay lines */
        AE_LSX2X2_IP(dx00, dx10, pDrd, 4*sizeof(float32_t));
        AE_LSX2X2_IP(dx11, dy00, pDrd, 4*sizeof(float32_t));
        AE_LSX2X2_IP(dy01, dy10, pDrd, 4*sizeof(float32_t));
        XT_LSX2IP(dy11, castxcc(xtfloatx2,pDrd), 4*sizeof(float32_t));
        
        /* load filter coefficients */
        AE_LSX2X2_I(b00, b01, (const xtfloatx4*)pb0,  0*sizeof(float32_t));
        AE_LSX2X2_I(b10, b11, (const xtfloatx4*)pb0,  4*sizeof(float32_t));
        AE_LSX2X2_I(b20, b21, (const xtfloatx4*)pb0,  8*sizeof(float32_t));
        AE_LSX2X2_I(a10, a11, (const xtfloatx4*)pb0, 12*sizeof(float32_t));
        AE_LSX2X2_X(a20, a21, (const xtfloatx4*)pb0, 16*sizeof(float32_t));

        /* processing loop */
        __Pragma("loop_count factor=2")
        for (n = 0; n < N; n++)
        {
            xtfloatx2 in0;
            ae_int32x2 tmp;
            /* load input sample */
            AE_L32_IP(tmp,castxcc(ae_int32,pX),sizeof(float32_t)); t=XT_AE_MOVXTFLOATX2_FROMINT32X2(tmp);

            in0=XT_SEL32_HH_SX2(t,dy01);
            /* perform multiplications for 4 biquads */
            MUL_SX2X2 (dz0, dz1, b20, b21, dx10, dx11);
            MSUB_SX2X2(dz0, dz1, a20, a21, dy10, dy11);
            MADD_SX2X2(dz0, dz1, b10, b11, dx00, dy10);
            MSUB_SX2X2(dz0, dz1, a10, a11, dy00, dy01);
            MADD_SX2X2(dz0, dz1, b00, b01, in0 , dy00);

            /* shift delay lines */
            dx11 = dy10;
            dx10 = dx00;
            dx00 = in0;
            dy10 = dy00;
            dy11 = dy01;
            dy00 = dz0;
            dy01 = dz1;

            /* save computed sample */
            tmp=XT_AE_MOVINT32X2_FROMXTFLOATX2(dz1);
            AE_S32_L_IP(tmp,castxcc(ae_int32,pZ),sizeof(float32_t));
        }
        /* jump to the next 4 sections */
        pb0 += 10;
        /* update delay lines */
        AE_SSX2X2_IP(dx00, dx10, pDwr, 4*sizeof(float32_t));
        AE_SSX2X2_IP(dx11, dy00, pDwr, 4*sizeof(float32_t));
        AE_SSX2X2_IP(dy01, dy10, pDwr, 4*sizeof(float32_t));
        XT_SSX2IP(dy11, castxcc(xtfloatx2,pDwr), 4*sizeof(float32_t));

        pX=(const ae_int32x2*)z;/* switch pointer to the input data to the pointer to the output */
    }
    __Pragma("no_reorder");
    /* Process last M%4 sections */
    M = M & 3;
    pb1 = (const xtfloatx2 *)((float32_t *)pb0+M);
    pb2 = (const xtfloatx2 *)((float32_t *)pb1+M);
    pa1 = (const xtfloatx2 *)((float32_t *)pb2+M);
    pa2 = (const xtfloatx2 *)((float32_t *)pa1+M);
    
    if (M == 3)
    {
        ae_valign al_cf;
        xtfloat t;
        pZ=(ae_int32x2 *)z;
        /* load delay lines */
        AE_LSX2X2_IP(dx00, dx10, pDrd, 4*sizeof(float32_t));
        AE_LSX2X2_IP(dx11, dy00, pDrd, 4*sizeof(float32_t));
        AE_LSX2X2_IP(dy01, dy10, pDrd, 4*sizeof(float32_t));
        dy11 = XT_SEL32_LL_SX2(dy01, dy01);
        
        /* load filter coefficients */
        al_cf = AE_LA64_PP(pb0); AE_LASX2IP(b00, al_cf, castxcc(const xtfloatx2,pb0)); AE_LSIP(t, castxcc(xtfloat,pb0), sizeof(float32_t)); b01=t;
        al_cf = AE_LA64_PP(pb1); AE_LASX2IP(b10, al_cf, castxcc(const xtfloatx2,pb1)); AE_LSIP(t, castxcc(xtfloat,pb1), sizeof(float32_t)); b11=t;
        al_cf = AE_LA64_PP(pb2); AE_LASX2IP(b20, al_cf, castxcc(const xtfloatx2,pb2)); AE_LSIP(t, castxcc(xtfloat,pb2), sizeof(float32_t)); b21=t;
        al_cf = AE_LA64_PP(pa1); AE_LASX2IP(a10, al_cf, castxcc(const xtfloatx2,pa1)); AE_LSIP(t, castxcc(xtfloat,pa1), sizeof(float32_t)); a11=t;
        al_cf = AE_LA64_PP(pa2); AE_LASX2IP(a20, al_cf, castxcc(const xtfloatx2,pa2)); AE_LSIP(t, castxcc(xtfloat,pa2), sizeof(float32_t)); a21=t;

        /* processing loop */
        __Pragma("loop_count factor=2")
        for (n = 0; n < N; n++)
        {
            xtfloatx2 in0;
            ae_int32x2 tmp;
            /* load input sample */
            AE_L32_IP(tmp,castxcc(ae_int32,pX),sizeof(float32_t)); t=XT_AE_MOVXTFLOATX2_FROMINT32X2(tmp);

            in0=XT_SEL32_HH_SX2(t,dy01);
            /* perform multiplications for 4 biquads */
            MUL_SX2X2 (dz0, dz1, b20, b21, dx10, dx11);
            MSUB_SX2X2(dz0, dz1, a20, a21, dy10, dy11);
            MADD_SX2X2(dz0, dz1, b10, b11, dx00, dy10);
            MSUB_SX2X2(dz0, dz1, a10, a11, dy00, dy01);
            MADD_SX2X2(dz0, dz1, b00, b01, in0 , dy00);

            /* shift delay lines */
            dx11 = dy10;
            dx10 = dx00;
            dx00 = in0;
            dy10 = dy00;
            dy11 = dy01;
            dy00 = dz0;
            dy01 = dz1;

            /* save computed sample */
            dz0 = MUL_SX2(dz0, scale);
            tmp=XT_AE_MOVINT32X2_FROMXTFLOATX2(dz0);
            AE_S32_L_IP(tmp,castxcc(ae_int32,pZ),sizeof(float32_t));
        }
        /* update delay lines */
        dy01 = XT_SEL32_HH_SX2(dy01, dy11);
        AE_SSX2X2_IP(dx00, dx10, pDwr, 4*sizeof(float32_t));
        AE_SSX2X2_IP(dx11, dy00, pDwr, 4*sizeof(float32_t));
        AE_SSX2X2_IP(dy01, dy10, pDwr, 4*sizeof(float32_t));
    }
    else if (M == 2)
    {
        xtfloat t;
        pZ=(ae_int32x2 *)z;
        /* load delay lines */
        AE_LSX2X2_IP(dx00, dx10, pDrd, 4*sizeof(float32_t));
        AE_LSX2X2_IP(dy00, dy10, pDrd, 4*sizeof(float32_t));
        dx11 = XT_SEL32_LL_SX2(dx10, dx10);
        dx10 = XT_SEL32_HH_SX2(dx10, dx10);
        dy11 = XT_SEL32_LL_SX2(dy10, dy10);
        dy10 = XT_SEL32_HH_SX2(dy10, dy10);
        dy01 = XT_SEL32_LL_SX2(dy00, dy00);
        dy00 = XT_SEL32_HH_SX2(dy00, dy00);
        /* load filter coefficients */
        XT_LSIP(t, castxcc(const xtfloat,pb0), sizeof(float32_t));  b00 = t;
        XT_LSIP(t, castxcc(const xtfloat,pb0), sizeof(float32_t));  b01 = t;
        XT_LSIP(t, castxcc(const xtfloat,pb1), sizeof(float32_t));  b10 = t;
        XT_LSIP(t, castxcc(const xtfloat,pb1), sizeof(float32_t));  b11 = t;
        XT_LSIP(t, castxcc(const xtfloat,pb2), sizeof(float32_t));  b20 = t;
        XT_LSIP(t, castxcc(const xtfloat,pb2), sizeof(float32_t));  b21 = t;
        XT_LSIP(t, castxcc(const xtfloat,pa1), sizeof(float32_t));  a10 = t;
        XT_LSIP(t, castxcc(const xtfloat,pa1), sizeof(float32_t));  a11 = t;
        XT_LSIP(t, castxcc(const xtfloat,pa2), sizeof(float32_t));  a20 = t;
        XT_LSIP(t, castxcc(const xtfloat,pa2), sizeof(float32_t));  a21 = t;
        
        /* processing loop */
        __Pragma("loop_count factor=2");
        for (n = 0; n < N; n++)
        {
            xtfloatx2 in0;
            ae_int32x2 tmp;
            /* load input sample */
            AE_L32_IP(tmp,castxcc(ae_int32,pX),sizeof(float32_t)); t=XT_AE_MOVXTFLOATX2_FROMINT32X2(tmp);

            in0=t;
            /* perform multiplications for 2 biquads */
            dz0 = MUL_SX2(b20, dx10);
            MADD_SX2(dz0, b10, dx00);
            MSUB_SX2(dz0, a20, dy10);
            MADD_SX2(dz0, b00, in0 );
            MSUB_SX2(dz0, a10, dy00);
            dz1 = MUL_SX2(b21, dx11);
            MADD_SX2(dz1, b11, dy10);
            MSUB_SX2(dz1, a21, dy11);
            MADD_SX2(dz1, b01, dy00);
            MSUB_SX2(dz1, a11, dy01);
            /* shift delay lines */
            dx11 = dy10;
            dy11 = dy01;
            dy01 = dz1;
            dy10 = dy00;
            dy00 = dz0;
            dx10 = dx00;
            dx00 = in0;
            /* save computed sample */
            dz1 = MUL_SX2(dz1, scale);
            tmp=XT_AE_MOVINT32X2_FROMXTFLOATX2(dz1);
            AE_S32_L_IP(tmp,castxcc(ae_int32,pZ),sizeof(float32_t));
        }
        /* update delay lines */
        dx10 = XT_SEL32_LL_SX2(dx10, dx11);
        dy10 = XT_SEL32_LL_SX2(dy10, dy11);
        dy00 = XT_SEL32_LL_SX2(dy00, dy01);
        AE_SSX2X2_IP(dx00, dx10, pDwr, 4*sizeof(float32_t));
        AE_SSX2X2_IP(dy00, dy10, pDwr, 4*sizeof(float32_t));
    }
    else if (M == 1)
    {
        xtfloat dx0,dx1,dy0,dy1,dz,t,sc0;
        xtfloat a1,a2,b0,b1,b2;
        pZ=(ae_int32x2 *)z;
        /* load delay lines */
        dx0 = XT_LSI((const xtfloat *)pDrd,0*sizeof(float32_t));
        dx1 = XT_LSI((const xtfloat *)pDrd,1*sizeof(float32_t));
        dy0 = XT_LSI((const xtfloat *)pDrd,2*sizeof(float32_t));
        dy1 = XT_LSI((const xtfloat *)pDrd,3*sizeof(float32_t));
        /* load coefficients */
        b0 = XT_LSI((const xtfloat *)pb0, 0);
        b1 = XT_LSI((const xtfloat *)pb1, 0);
        b2 = XT_LSI((const xtfloat *)pb2, 0);
        a1 = XT_LSI((const xtfloat *)pa1, 0);
        a2 = XT_LSI((const xtfloat *)pa2, 0);
        sc0 = scale;
        /* processing loop */
        __Pragma("loop_count factor=2");
        for (n = 0; n < N; n++)
        {
            XT_LSIP(t,castxcc(xtfloat,pX),sizeof(float32_t));
            dz = MUL_S(b2,dx1);
            MADD_S(dz,b1,dx0);
            MSUB_S(dz,a2,dy1);
            MADD_S(dz,b0,t  );
            MSUB_S(dz,a1,dy0);
            dy1=dy0;
            dy0=dz ;
            dx1=dx0;
            dx0=t;

            dz = MUL_S(dz, sc0);
            XT_SSIP(dz,castxcc(xtfloat,pZ),sizeof(float32_t));
        }
        XT_SSI(dx0,(xtfloat *)pDwr,0*sizeof(float32_t));
        XT_SSI(dx1,(xtfloat *)pDwr,1*sizeof(float32_t));
        XT_SSI(dy0,(xtfloat *)pDwr,2*sizeof(float32_t));
        XT_SSI(dy1,(xtfloat *)pDwr,3*sizeof(float32_t));
    }
    // final scaling; used when the number of sections is multiple of 4
    else
    {
        xtfloatx2 x0, x1;
        ae_valignx2 alX, alZ;
        pZ = (ae_int32x2 *)z;
        alX = AE_LA128_PP(pX);
        alZ = AE_ZALIGN128();
        __Pragma("ymemory (pZ)");
        for (n = 0; n < (N>>2); n++)
        {
            AE_LASX2X2_IP(x0, x1, alX, castxcc(xtfloatx4,pX));
            MUL_SX2X2(x0, x1, x0, x1, scale, scale);
            AE_SASX2X2_IP(x0, x1, alZ, castxcc(xtfloatx4,pZ));
        }
        AE_SA128POS_FP(alZ, pZ);
        if (N & 2)
        {
            ae_valign al_px, al_pz;
            al_pz = AE_ZALIGN64();

            al_px = AE_LA64_PP(pX);
            AE_LASX2IP(x0, al_px, castxcc(xtfloatx2,pX));
            x0 = MUL_SX2(x0, scale);
            AE_SASX2IP(x0, al_pz, castxcc(xtfloatx2,pZ));
            AE_SA64POS_FP(al_pz, pZ);
        }
    }
}/* bqriirf_df1_process() */
#else
// for scalar FPU
void bqriirf_df1( bqriirf_df1_handle_t restrict _bqriir,
                  float32_t *                   z,
            const float32_t *                   x, int N)
{
#define VLEN 4  /* vector length */
    bqriirf_df1_t *state;
    const xtfloat * restrict pDrd;
          xtfloat * restrict pDwr;
    const xtfloat * restrict pSos;
    const xtfloat * pX;
          xtfloat * pZ;
    const xtfloat * restrict pXr;
          xtfloat * restrict pZr;

    float32_t scale;
    int32_t s;
    int n,m,p;
    int M,P;
    NASSERT(_bqriir);
    state=(bqriirf_df1_t*)(_bqriir);
    if(N<=0) return;
    NASSERT(N%2==0);
    NASSERT(x);
    NASSERT(z);
    NASSERT(state);
    NASSERT(state->st);
    NASSERT(state->cf);
    M=state->M;
    pDrd=(const       xtfloat *)state->st;
    pDwr=(xtfloat *)state->st;
    s=state->gain;
    s=((s+127)&255)<<23;
    scale=XT_WFR(s);

    pSos=(const xtfloat *)state->cf;
    for (m=0; m<M; m+=VLEN)
    {
        xtfloat dx0,dx1,dy0,dy1,dz;
        xtfloat a1 ,a2 ,b0 ,b1 ,b2;

        P = XT_MIN(VLEN, M-m);
        for (p=0; p<P-1; p++)
        {
            /* load delay lines and coefficients */
            pX=(const xtfloat*)x;
            pZ=(      xtfloat*)z;
            XT_LSIP(dx0,pDrd,sizeof(xtfloat));
            XT_LSIP(dx1,pDrd,sizeof(xtfloat));
            XT_LSIP(dy0,pDrd,sizeof(xtfloat));
            XT_LSIP(dy1,pDrd,sizeof(xtfloat));
            XT_LSIP(b0 ,pSos,sizeof(xtfloat));
            XT_LSIP(b1 ,pSos,sizeof(xtfloat));
            XT_LSIP(b2 ,pSos,sizeof(xtfloat));
            XT_LSIP(a1 ,pSos,sizeof(xtfloat));
            XT_LSIP(a2 ,pSos,sizeof(xtfloat));
            for (n=0;n<N;n+=2)
            {
                xtfloat t0,t1;
                XT_LSIP(t0,pX,sizeof(xtfloat));
                XT_LSIP(t1,pX,sizeof(xtfloat));
                XT_SSIP(dy0,pZ,sizeof(xtfloat));
                dz=XT_MUL_S (b2,dx1);
                XT_MADD_S(dz,b1,dx0);
                XT_MSUB_S(dz,a2,dy1);
                XT_MADD_S(dz,b0,t0 );
                XT_MSUB_S(dz,a1,dy0);
                dy1=dy0;
                dy0=dz ;
                dx1=dx0;
                dx0=t0;
                XT_SSIP(dy0,pZ,sizeof(xtfloat));
                dz=XT_MUL_S (b2,dx1);
                XT_MADD_S(dz,b1,dx0);
                XT_MSUB_S(dz,a2,dy1);
                XT_MADD_S(dz,b0,t1 );
                XT_MSUB_S(dz,a1,dy0);
                dy1=dy0;
                dy0=dz ;
                dx1=dx0;
                dx0=t1;
            }
            XT_SSIP(dx0,pDwr,sizeof(xtfloat));
            XT_SSIP(dx1,pDwr,sizeof(xtfloat));
            XT_SSIP(dy0,pDwr,sizeof(xtfloat));
            XT_SSIP(dy1,pDwr,sizeof(xtfloat));
            x=z;
        }
        pX=(const xtfloat*)x;
        pZ=(      xtfloat*)z;
        XT_LSIP(dx0,pDrd,sizeof(xtfloat));
        XT_LSIP(dx1,pDrd,sizeof(xtfloat));
        XT_LSIP(dy0,pDrd,sizeof(xtfloat));
        XT_LSIP(dy1,pDrd,sizeof(xtfloat));
        XT_LSIP(b0 ,pSos,sizeof(xtfloat));
        XT_LSIP(b1 ,pSos,sizeof(xtfloat));
        XT_LSIP(b2 ,pSos,sizeof(xtfloat));
        XT_LSIP(a1 ,pSos,sizeof(xtfloat));
        XT_LSIP(a2 ,pSos,sizeof(xtfloat));
        for (n=0;n<N;n+=2)
        {
            xtfloat t0,t1;
            XT_LSIP(t0,pX,sizeof(xtfloat));
            XT_LSIP(t1,pX,sizeof(xtfloat));
            dz=XT_MUL_S (b2,dx1);
            XT_MADD_S(dz,b1,dx0);
            XT_MSUB_S(dz,a2,dy1);
            XT_MADD_S(dz,b0,t0 );
            XT_MSUB_S(dz,a1,dy0);
            dy1=dy0;
            dy0=dz ;
            dx1=dx0;
            dx0=t0 ;
            XT_SSIP(dz,pZ,sizeof(xtfloat));
            dz=XT_MUL_S (b2,dx1);
            XT_MADD_S(dz,b1,dx0);
            XT_MSUB_S(dz,a2,dy1);
            XT_MADD_S(dz,b0,t1 );
            XT_MSUB_S(dz,a1,dy0);
            dy1=dy0;
            dy0=dz ;
            dx1=dx0;
            dx0=t1 ;
            XT_SSIP(dz,pZ,sizeof(xtfloat));
        }
        /* save delay lines  */
        XT_SSIP(dx0,pDwr,sizeof(xtfloat));
        XT_SSIP(dx1,pDwr,sizeof(xtfloat));
        XT_SSIP(dy0,pDwr,sizeof(xtfloat));
        XT_SSIP(dy1,pDwr,sizeof(xtfloat));
        x=z;
    }
    __Pragma("no_reorder")
    /* final scaling */
    {
        pZr=(      xtfloat*)z;
        pXr=(const xtfloat*)x;
        for (n=0; n<(N>>1); n++)
        {
            xtfloat x0,x1;
            XT_LSIP(x0,pXr,sizeof(xtfloat));
            XT_LSIP(x1,pXr,sizeof(xtfloat));
            XT_SSIP(XT_MUL_S(x0,scale),pZr,sizeof(xtfloat));
            XT_SSIP(XT_MUL_S(x1,scale),pZr,sizeof(xtfloat));
        }
    }
#undef VLEN
}
#endif
